{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4864b13-67d1-4421-b550-214df674edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "SMOTE增强与XGBoost分类的严谨实验框架 (消融研究对比版本)\n",
    "=========================================================\n",
    "本脚本是为响应审稿人“消融研究”要求而创建的对比实验版本。\n",
    "它使用SMOTE作为数据增强方法，与WGAN-GP版本形成直接对比。\n",
    "\n",
    "核心方法学与WGAN-GP版本保持一致，以确保对比的公平性：\n",
    "1.  **严格的数据隔离**: 独立的“开发集”和“最终测试集”。\n",
    "2.  **动态嵌套式数据增强**: 在K-折交叉验证的每一折内部，动态地使用SMOTE增强当前折的训练数据。\n",
    "3.  **混合数据类型处理**: SMOTE应用于预处理后的数据空间，生成样本后再逆转换为原始格式。\n",
    "4.  **正确的模型与评估**: 全程使用XGBoost分类器及分类指标。\n",
    "\"\"\"\n",
    "\n",
    "# --- 基础库导入 ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, ConfusionMatrixDisplay,\n",
    "                             make_scorer)\n",
    "# SMOTE需要从imblearn库导入\n",
    "# 如果您尚未安装，请运行: pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 0. 全局配置 (与WGAN-GP版本完全一致) ---\n",
    "\n",
    "# --- 路径配置 ---\n",
    "CURRENT_DIR = Path.cwd()\n",
    "PROJECT_ROOT = CURRENT_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "\n",
    "DEV_SET_FILE = DATA_DIR / \"development_set.xlsx\"\n",
    "TEST_SET_FILE = DATA_DIR / \"final_test_set.xlsx\"\n",
    "# 为SMOTE版本创建独立的输出文件夹，以避免与WGAN-GP版本的结果混淆\n",
    "SMOTE_OUTPUT_DIR = OUTPUT_DIR / \"smote_experiment\"\n",
    "AUGMENTED_DATA_OUTPUT_FOLDER = SMOTE_OUTPUT_DIR / \"augmented_outputs\"\n",
    "MODEL_OUTPUT_PATH = SMOTE_OUTPUT_DIR / \"trained_models\"\n",
    "OUTPUT_PLOT_PATH = SMOTE_OUTPUT_DIR\n",
    "\n",
    "os.makedirs(AUGMENTED_DATA_OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# --- 实验参数 ---\n",
    "TARGET_COLUMN = 'target'\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS_KFOLD = 5\n",
    "\n",
    "# --- XGBoost RandomizedSearchCV 超参数搜索空间 ---\n",
    "XGB_PARAM_GRID = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0.5, 1, 1.5],\n",
    "    'scale_pos_weight': [1, 5, 10, 20]\n",
    "}\n",
    "N_ITER_RANDOMIZED_SEARCH = 30\n",
    "\n",
    "# --- 设备配置 ---\n",
    "# SMOTE在CPU上运行，但XGBoost仍可利用GPU\n",
    "# 检查torch是否可用，以决定设备类型。如果torch不可用，则默认为'cpu'。\n",
    "try:\n",
    "    import torch\n",
    "    device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "except ImportError:\n",
    "    device_type = 'cpu'\n",
    "print(f\"XGBoost将使用设备: {device_type}\")\n",
    "\n",
    "\n",
    "# --- 数据特征定义 ---\n",
    "CONTINUOUS_COLS = ['age', 'restingBP', 'serumcholestrol', 'maxheartrate', 'oldpeak']\n",
    "CATEGORICAL_COLS = ['gender', 'fastingbloodsugar', 'chestpain',\n",
    "                    'restingrelectro', 'exerciseangia', 'slope',\n",
    "                    'noofmajorvessels', 'target']\n",
    "\n",
    "CATEGORY_MAPPINGS = {\n",
    "    'gender':           [0, 1],\n",
    "    'fastingbloodsugar':[0, 1],\n",
    "    'chestpain':        [0, 1, 2, 3],\n",
    "    'restingrelectro':  [0, 1, 2],\n",
    "    'exerciseangia':    [0, 1],\n",
    "    'slope':            [1, 2, 3],\n",
    "    'noofmajorvessels': [0, 1, 2, 3],\n",
    "    'target':           [0, 1]\n",
    "}\n",
    "\n",
    "CONTINUOUS_BOUNDS = {\n",
    "    'age':              (20, 80),\n",
    "    'restingBP':        (94, 200),\n",
    "    'serumcholestrol':  (126, 564),\n",
    "    'maxheartrate':     (71, 202),\n",
    "    'oldpeak':          (0, 6.2)\n",
    "}\n",
    "\n",
    "# --- 1. SMOTE 数据增强核心功能函数 ---\n",
    "def augment_with_smote(input_original_df,\n",
    "                       fold_num_for_logging=None,\n",
    "                       output_augmented_data_path=None):\n",
    "    \"\"\"\n",
    "    一个完整的函数，用于使用SMOTE生成指定数量的增强样本。\n",
    "    该函数封装了所有预处理、SMOTE应用和后处理步骤。\n",
    "    \"\"\"\n",
    "    log_prefix = f\"[SMOTE\"\n",
    "    if fold_num_for_logging:\n",
    "        log_prefix += f\" {fold_num_for_logging}\"\n",
    "    log_prefix += \"]\"\n",
    "    print(f\"\\n{log_prefix}] 开始数据增强，输入形状: {input_original_df.shape}\")\n",
    "\n",
    "    # 1. 预处理：拆分、标准化、独热编码\n",
    "    cont_df = input_original_df[CONTINUOUS_COLS]\n",
    "    cat_df  = input_original_df[CATEGORICAL_COLS]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    cont_std = scaler.fit_transform(cont_df)\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype=np.float32, handle_unknown='ignore')\n",
    "    cat_oh  = encoder.fit_transform(cat_df)\n",
    "    \n",
    "    X_processed = np.hstack([cont_std, cat_oh])\n",
    "    y_original = input_original_df[TARGET_COLUMN]\n",
    "\n",
    "    # 2. 应用SMOTE (修正后的鲁棒版本)\n",
    "    # 动态确定少数类和多数类\n",
    "    class_counts = y_original.value_counts()\n",
    "    \n",
    "    # 如果只有一个类别，或者类别已经平衡，则不进行增强\n",
    "    if len(class_counts) < 2 or class_counts.iloc[0] == class_counts.iloc[1]:\n",
    "        print(f\"{log_prefix}] 数据已平衡或只有一个类别，跳过SMOTE。\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    majority_class_label = class_counts.idxmax()\n",
    "    minority_class_label = class_counts.idxmin()\n",
    "    n_majority = class_counts[majority_class_label]\n",
    "    n_minority = class_counts[minority_class_label]\n",
    "    \n",
    "    # 设置采样策略：将少数类的样本数增加到与多数类相同\n",
    "    sampling_strategy = {minority_class_label: n_majority}\n",
    "    \n",
    "    print(f\"{log_prefix}] 应用SMOTE... 原始少数类({minority_class_label})样本数: {n_minority}, 多数类({majority_class_label})样本数: {n_majority}\")\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy, random_state=RANDOM_STATE)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_processed, y_original)\n",
    "    \n",
    "    # 提取新生成的样本\n",
    "    num_original_samples = len(input_original_df)\n",
    "    generated_processed = X_resampled[num_original_samples:]\n",
    "    \n",
    "    if len(generated_processed) == 0:\n",
    "        print(f\"{log_prefix}] 警告: SMOTE未生成新样本。返回空DataFrame。\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    print(f\"{log_prefix}] SMOTE完成，生成了 {len(generated_processed)} 个新样本。\")\n",
    "\n",
    "    # 3. 后处理：反变换与数据还原\n",
    "    num_cont_cols = len(CONTINUOUS_COLS)\n",
    "    gen_cont_std = generated_processed[:, :num_cont_cols]\n",
    "    gen_cat_oh   = generated_processed[:, num_cont_cols:]\n",
    "\n",
    "    gen_cont = scaler.inverse_transform(gen_cont_std)\n",
    "    for i, col in enumerate(CONTINUOUS_COLS):\n",
    "        lo, hi = CONTINUOUS_BOUNDS[col]\n",
    "        gen_cont[:, i] = np.clip(gen_cont[:, i], lo, hi)\n",
    "\n",
    "    # 使用与WGAN-GP版本相同的鲁棒反变换逻辑\n",
    "    gen_cat_df = pd.DataFrame(columns=CATEGORICAL_COLS)\n",
    "    current_col_idx = 0\n",
    "    for i, col in enumerate(CATEGORICAL_COLS):\n",
    "        num_categories = len(encoder.categories_[i])\n",
    "        col_slice = gen_cat_oh[:, current_col_idx : current_col_idx + num_categories]\n",
    "        cat_indices = np.argmax(col_slice, axis=1)\n",
    "        original_labels = encoder.categories_[i][cat_indices]\n",
    "        gen_cat_df[col] = original_labels\n",
    "        current_col_idx += num_categories\n",
    "\n",
    "    for col in CATEGORICAL_COLS:\n",
    "        gen_cat_df[col] = pd.to_numeric(gen_cat_df[col], errors='coerce')\n",
    "        gen_cat_df[col] = gen_cat_df[col].apply(\n",
    "            lambda x: min(CATEGORY_MAPPINGS[col], key=lambda v: abs(v - x)) if pd.notna(x) else x\n",
    "        )\n",
    "\n",
    "    # 4. 合并为最终的DataFrame\n",
    "    augmented_df = pd.DataFrame(gen_cont, columns=CONTINUOUS_COLS)\n",
    "    augmented_df[CATEGORICAL_COLS] = gen_cat_df\n",
    "\n",
    "    # 5. (可选) 保存到文件\n",
    "    if output_augmented_data_path:\n",
    "        augmented_df.to_excel(output_augmented_data_path, index=False)\n",
    "        print(f\"{log_prefix}] 增强数据已保存到: {output_augmented_data_path}\")\n",
    "\n",
    "    return augmented_df\n",
    "\n",
    "# --- 2. 主流程开始 ---\n",
    "try:\n",
    "    development_df_original = pd.read_excel(DEV_SET_FILE)\n",
    "    final_test_df_original = pd.read_excel(TEST_SET_FILE)\n",
    "    print(f\"成功加载数据: 开发集形状 {development_df_original.shape}, 最终测试集形状 {final_test_df_original.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误: 数据文件未找到，请检查路径。 {e}\")\n",
    "    exit()\n",
    "\n",
    "X_dev_original = development_df_original.drop(columns=[TARGET_COLUMN])\n",
    "y_dev_original = development_df_original[TARGET_COLUMN]\n",
    "X_final_test = final_test_df_original.drop(columns=[TARGET_COLUMN])\n",
    "y_final_test = final_test_df_original[TARGET_COLUMN]\n",
    "\n",
    "# --- 步骤 3.1: 超参数调优 (HPO) ---\n",
    "print(\"\\n--- [步骤 3.1] XGBoost 超参数调优 (使用SMOTE增强) ---\")\n",
    "print(\"为HPO生成开发集的SMOTE增强版本...\")\n",
    "augmented_dev_for_hpo_df = augment_with_smote(\n",
    "    input_original_df=development_df_original.copy(),\n",
    "    fold_num_for_logging=\"HPO_Dev_Set\"\n",
    ")\n",
    "\n",
    "# 检查增强是否成功\n",
    "if not augmented_dev_for_hpo_df.empty:\n",
    "    X_augmented_dev_for_hpo = augmented_dev_for_hpo_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_augmented_dev_for_hpo = augmented_dev_for_hpo_df[TARGET_COLUMN]\n",
    "    X_combined_dev_for_hpo = pd.concat([X_dev_original, X_augmented_dev_for_hpo], ignore_index=True)\n",
    "    y_combined_dev_for_hpo = pd.concat([y_dev_original, y_augmented_dev_for_hpo], ignore_index=True)\n",
    "else:\n",
    "    print(\"HPO阶段数据增强未生成样本，仅使用原始数据进行调优。\")\n",
    "    X_combined_dev_for_hpo = X_dev_original\n",
    "    y_combined_dev_for_hpo = y_dev_original\n",
    "\n",
    "\n",
    "xgb_classifier_for_hpo = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss',\n",
    "                                           random_state=RANDOM_STATE, use_label_encoder=False,\n",
    "                                           tree_method='gpu_hist' if device_type == 'cuda' else 'auto')\n",
    "\n",
    "random_search_hpo = RandomizedSearchCV(\n",
    "    estimator=xgb_classifier_for_hpo, param_distributions=XGB_PARAM_GRID,\n",
    "    n_iter=N_ITER_RANDOMIZED_SEARCH, cv=N_SPLITS_KFOLD,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "print(f\"开始在 {X_combined_dev_for_hpo.shape[0]} 个样本上进行XGBoost超参数搜索...\")\n",
    "random_search_hpo.fit(X_combined_dev_for_hpo, y_combined_dev_for_hpo)\n",
    "best_overall_xgboost_params = random_search_hpo.best_params_\n",
    "print(f\"\\n找到的最佳XGBoost超参数 (SMOTE): {best_overall_xgboost_params}\")\n",
    "print(f\"最佳HPO ROC AUC Score (SMOTE): {random_search_hpo.best_score_:.4f}\")\n",
    "\n",
    "# --- 步骤 3.2: K-折交叉验证与动态SMOTE增强 ---\n",
    "print(f\"\\n--- [步骤 3.2] 在开发集上进行 {N_SPLITS_KFOLD}-折交叉验证 (动态SMOTE增强) ---\")\n",
    "kf = KFold(n_splits=N_SPLITS_KFOLD, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "kfold_cv_val_metrics_list = []\n",
    "kfold_cv_train_metrics_list = []\n",
    "cv_train_loss_curves = []\n",
    "cv_val_loss_curves = []\n",
    "\n",
    "for fold_idx, (train_indices, val_indices) in enumerate(kf.split(development_df_original)):\n",
    "    print(f\"\\n--- K-Fold: 第 {fold_idx + 1}/{N_SPLITS_KFOLD} 折 ---\")\n",
    "    cv_train_original_fold_df = development_df_original.iloc[train_indices]\n",
    "    cv_val_original_fold_df = development_df_original.iloc[val_indices]\n",
    "\n",
    "    cv_augmented_fold_df = augment_with_smote(\n",
    "        input_original_df=cv_train_original_fold_df.copy(),\n",
    "        fold_num_for_logging=f\"Fold_{fold_idx + 1}\"\n",
    "    )\n",
    "\n",
    "    X_cv_train_original_fold = cv_train_original_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_train_original_fold = cv_train_original_fold_df[TARGET_COLUMN]\n",
    "    \n",
    "    if not cv_augmented_fold_df.empty:\n",
    "        X_cv_augmented_fold = cv_augmented_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "        y_cv_augmented_fold = cv_augmented_fold_df[TARGET_COLUMN]\n",
    "        X_cv_train_combined_fold = pd.concat([X_cv_train_original_fold, X_cv_augmented_fold], ignore_index=True)\n",
    "        y_cv_train_combined_fold = pd.concat([y_cv_train_original_fold, y_cv_augmented_fold], ignore_index=True)\n",
    "    else:\n",
    "        X_cv_train_combined_fold = X_cv_train_original_fold\n",
    "        y_cv_train_combined_fold = y_cv_train_original_fold\n",
    "\n",
    "    \n",
    "    X_cv_val_fold = cv_val_original_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_val_fold = cv_val_original_fold_df[TARGET_COLUMN]\n",
    "\n",
    "    model_fold = xgb.XGBClassifier(\n",
    "        **best_overall_xgboost_params, objective='binary:logistic', eval_metric='logloss',\n",
    "        random_state=RANDOM_STATE, use_label_encoder=False,\n",
    "        tree_method='gpu_hist' if device_type == 'cuda' else 'auto'\n",
    "    )\n",
    "    \n",
    "    eval_set_fold = [(X_cv_train_combined_fold, y_cv_train_combined_fold), (X_cv_val_fold, y_cv_val_fold)]\n",
    "    model_fold.fit(X_cv_train_combined_fold, y_cv_train_combined_fold,\n",
    "                   eval_set=eval_set_fold, early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "    fold_eval_results = model_fold.evals_result()\n",
    "    cv_train_loss_curves.append(fold_eval_results['validation_0']['logloss'])\n",
    "    cv_val_loss_curves.append(fold_eval_results['validation_1']['logloss'])\n",
    "\n",
    "    y_pred_val_proba = model_fold.predict_proba(X_cv_val_fold)[:, 1]\n",
    "    y_pred_val = (y_pred_val_proba > 0.5).astype(int)\n",
    "    kfold_cv_val_metrics_list.append({\n",
    "        'Accuracy': accuracy_score(y_cv_val_fold, y_pred_val),\n",
    "        'F1 Score': f1_score(y_cv_val_fold, y_pred_val),\n",
    "        'AUC': roc_auc_score(y_cv_val_fold, y_pred_val_proba)\n",
    "    })\n",
    "\n",
    "    y_pred_train_proba = model_fold.predict_proba(X_cv_train_combined_fold)[:, 1]\n",
    "    y_pred_train = (y_pred_train_proba > 0.5).astype(int)\n",
    "    kfold_cv_train_metrics_list.append({\n",
    "        'Accuracy': accuracy_score(y_cv_train_combined_fold, y_pred_train),\n",
    "        'F1 Score': f1_score(y_cv_train_combined_fold, y_pred_train),\n",
    "        'AUC': roc_auc_score(y_cv_train_combined_fold, y_pred_train_proba)\n",
    "    })\n",
    "    print(f\"Fold {fold_idx + 1} - Val AUC: {kfold_cv_val_metrics_list[-1]['AUC']:.4f} | Train AUC: {kfold_cv_train_metrics_list[-1]['AUC']:.4f}\")\n",
    "\n",
    "# --- 步骤 3.3: 交叉验证结果分析与可视化 ---\n",
    "avg_kfold_cv_val_metrics_df = pd.DataFrame(kfold_cv_val_metrics_list)\n",
    "avg_kfold_cv_train_metrics_df = pd.DataFrame(kfold_cv_train_metrics_list)\n",
    "\n",
    "print(\"\\n--- K-折交叉验证平均性能 (SMOTE动态增强) ---\")\n",
    "print(\"--- 平均验证集性能 ---\")\n",
    "print(avg_kfold_cv_val_metrics_df.mean())\n",
    "print(\"\\n--- 平均训练集性能 ---\")\n",
    "print(avg_kfold_cv_train_metrics_df.mean())\n",
    "\n",
    "avg_val_metrics = avg_kfold_cv_val_metrics_df.mean()\n",
    "avg_train_metrics = avg_kfold_cv_train_metrics_df.mean()\n",
    "metrics_to_plot = ['Accuracy', 'F1 Score', 'AUC']\n",
    "x_axis = np.arange(len(metrics_to_plot))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_axis - 0.2, avg_train_metrics[metrics_to_plot], width=0.4, label='CV Train Avg.', align='center')\n",
    "plt.bar(x_axis + 0.2, avg_val_metrics[metrics_to_plot], width=0.4, label='CV Validation Avg.', align='center')\n",
    "plt.xticks(x_axis, metrics_to_plot)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Average K-Fold CV Train vs. Validation Metrics (SMOTE Augmented)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.savefig(OUTPUT_PLOT_PATH / \"kfold_avg_eval_metrics_smote.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "for i in range(N_SPLITS_KFOLD):\n",
    "    plt.plot(cv_train_loss_curves[i], label=f'Train Fold {i+1}', linestyle='--')\n",
    "    plt.plot(cv_val_loss_curves[i], label=f'Validation Fold {i+1}', linestyle='-')\n",
    "plt.xlabel('Boosting Round')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('Training and Validation Log Loss per Fold (SMOTE Augmented)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.savefig(OUTPUT_PLOT_PATH / \"kfold_logloss_per_fold_smote.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- 步骤 4: 训练最终模型 ---\n",
    "print(\"\\n--- [步骤 4] 训练最终模型 (使用SMOTE增强) ---\")\n",
    "print(\"为最终模型生成开发集的完整SMOTE增强版本...\")\n",
    "final_augmented_dev_df = augment_with_smote(\n",
    "    input_original_df=development_df_original.copy(),\n",
    "    fold_num_for_logging=\"Final_Model_Augmentation\",\n",
    "    output_augmented_data_path=AUGMENTED_DATA_OUTPUT_FOLDER / \"augmented_for_final_model_smote.xlsx\"\n",
    ")\n",
    "\n",
    "if not final_augmented_dev_df.empty:\n",
    "    X_final_augmented_dev = final_augmented_dev_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_final_augmented_dev = final_augmented_dev_df[TARGET_COLUMN]\n",
    "    X_train_final_model = pd.concat([X_dev_original, X_final_augmented_dev], ignore_index=True)\n",
    "    y_train_final_model = pd.concat([y_dev_original, y_final_augmented_dev], ignore_index=True)\n",
    "else:\n",
    "    print(\"最终模型训练阶段数据增强未生成样本，仅使用原始数据进行训练。\")\n",
    "    X_train_final_model = X_dev_original\n",
    "    y_train_final_model = y_dev_original\n",
    "\n",
    "print(f\"用于训练最终模型的总数据形状: {X_train_final_model.shape}\")\n",
    "\n",
    "final_model = xgb.XGBClassifier(\n",
    "    **best_overall_xgboost_params, objective='binary:logistic', eval_metric='logloss',\n",
    "    random_state=RANDOM_STATE, use_label_encoder=False,\n",
    "    tree_method='gpu_hist' if device_type == 'cuda' else 'auto'\n",
    ")\n",
    "print(\"开始训练最终模型...\")\n",
    "final_model.fit(X_train_final_model, y_train_final_model)\n",
    "print(\"最终模型训练完成。\")\n",
    "\n",
    "final_model_path = MODEL_OUTPUT_PATH / \"final_xgboost_smote_model.joblib\"\n",
    "joblib.dump(final_model, final_model_path)\n",
    "print(f\"最终模型已保存到: {final_model_path}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "xgb.plot_importance(final_model, max_num_features=20, height=0.8, title=\"Feature Importance (Final Model with SMOTE)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PLOT_PATH / \"final_model_feature_importances_smote.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- 步骤 5: 在最终测试集上进行无偏评估 ---\n",
    "print(\"\\n--- [步骤 5] 在最终测试集上进行无偏评估 (SMOTE模型) ---\")\n",
    "y_pred_proba_final = final_model.predict_proba(X_final_test)[:, 1]\n",
    "y_pred_final = (y_pred_proba_final >= 0.5).astype(int)\n",
    "\n",
    "print(\"--- 最终模型在最终测试集上的性能 (SMOTE) ---\")\n",
    "print(f\"Accuracy : {accuracy_score(y_final_test, y_pred_final):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_final_test, y_pred_final):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_final_test, y_pred_final):.4f}\")\n",
    "print(f\"F1 Score : {f1_score(y_final_test, y_pred_final):.4f}\")\n",
    "print(f\"AUC      : {roc_auc_score(y_final_test, y_pred_proba_final):.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ConfusionMatrixDisplay.from_predictions(y_final_test, y_pred_final,\n",
    "                                        ax=ax,\n",
    "                                        display_labels=['Absence', 'Presence'],\n",
    "                                        cmap='Blues')\n",
    "ax.set_title('Confusion Matrix on Final Test Set (SMOTE Model)')\n",
    "plt.savefig(OUTPUT_PLOT_PATH / \"final_model_confusion_matrix_smote.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- SMOTE版本整体流程执行完毕 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63dde6-78df-42d0-9639-f373b145e927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xgb_gpu_env)",
   "language": "python",
   "name": "xgb_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
